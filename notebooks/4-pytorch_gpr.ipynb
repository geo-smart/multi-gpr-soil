{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b011d16-5e73-46f5-9e0d-3443ec2ff42b",
   "metadata": {},
   "source": [
    "# Pytorch Multi-output GPR\n",
    "\n",
    "The purpose of this notebook is to predict the soil type and soil thickness of Layer 1 as a Multi-Output GP model using a ModelList. Unlike a Multi-Task model, Multi-Output models do not represent correlations between outcomes, but treat outcomes independently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb804bf-e961-4804-a088-3f113bb7381f",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69f4200-2066-4eab-96a2-c7eba0136384",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch --quiet\n",
    "!pip install gpytorch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e264b31-4228-4088-9235-9c5cc3f99f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.models import ApproximateGP, ExactGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy\n",
    "from gpytorch.likelihoods import SoftmaxLikelihood, GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13712b6b-e473-4e08-861a-1a4885d4eeff",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa664a05-0bd2-453a-9e5d-9068ce2cd200",
   "metadata": {},
   "source": [
    "#### Load training data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f4ce29-8f04-48e9-9944-01b8f6e4d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOREHOLE_ID</th>\n",
       "      <th>BOREHOLE_NAME</th>\n",
       "      <th>BOREHOLE_TYPE</th>\n",
       "      <th>BOREHOLE_DEPTH_FT</th>\n",
       "      <th>ELEVATION_FT</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LAYER_NUMBER</th>\n",
       "      <th>TOP_DEPTH_FT</th>\n",
       "      <th>BOTTOM_DEPTH_FT</th>\n",
       "      <th>USCS</th>\n",
       "      <th>SIMPLE_USCS</th>\n",
       "      <th>LAYER_THICKNESS_FT</th>\n",
       "      <th>geometry</th>\n",
       "      <th>MAPPED_UNIT</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>ROUGHNESS</th>\n",
       "      <th>GEOMORPHON</th>\n",
       "      <th>VS30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>EB-1</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>41.0</td>\n",
       "      <td>131.30</td>\n",
       "      <td>47.575005</td>\n",
       "      <td>-122.406037</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>OH</td>\n",
       "      <td>O</td>\n",
       "      <td>2.5</td>\n",
       "      <td>POINT (-122.40604 47.575)</td>\n",
       "      <td>Ql</td>\n",
       "      <td>8.126739</td>\n",
       "      <td>36.531616</td>\n",
       "      <td>6.0</td>\n",
       "      <td>647.38780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>EB-2</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>40.0</td>\n",
       "      <td>130.90</td>\n",
       "      <td>47.574982</td>\n",
       "      <td>-122.406239</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>POINT (-122.40624 47.57498)</td>\n",
       "      <td>Ql</td>\n",
       "      <td>8.056191</td>\n",
       "      <td>38.262520</td>\n",
       "      <td>6.0</td>\n",
       "      <td>647.38780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>HB-1</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>10.5</td>\n",
       "      <td>46.30</td>\n",
       "      <td>47.512358</td>\n",
       "      <td>-122.394125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>ML</td>\n",
       "      <td>M</td>\n",
       "      <td>7.5</td>\n",
       "      <td>POINT (-122.39412 47.51236)</td>\n",
       "      <td>Qss</td>\n",
       "      <td>12.098481</td>\n",
       "      <td>45.003693</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>HB-2</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>6.9</td>\n",
       "      <td>47.70</td>\n",
       "      <td>47.512384</td>\n",
       "      <td>-122.394069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ML</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>POINT (-122.39407 47.51238)</td>\n",
       "      <td>Qss</td>\n",
       "      <td>12.098481</td>\n",
       "      <td>45.003693</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>HB-3</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>13.5</td>\n",
       "      <td>40.90</td>\n",
       "      <td>47.512208</td>\n",
       "      <td>-122.394083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>ML</td>\n",
       "      <td>M</td>\n",
       "      <td>8.6</td>\n",
       "      <td>POINT (-122.39408 47.51221)</td>\n",
       "      <td>Qss</td>\n",
       "      <td>12.098481</td>\n",
       "      <td>45.003693</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10501</th>\n",
       "      <td>153201</td>\n",
       "      <td>B-1</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>44.0</td>\n",
       "      <td>26.35</td>\n",
       "      <td>47.437003</td>\n",
       "      <td>-122.242410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>POINT (-122.24241 47.437)</td>\n",
       "      <td>Qaw</td>\n",
       "      <td>0.373783</td>\n",
       "      <td>1.591432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.62921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10502</th>\n",
       "      <td>153202</td>\n",
       "      <td>B-2</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>39.0</td>\n",
       "      <td>24.45</td>\n",
       "      <td>47.437208</td>\n",
       "      <td>-122.242890</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ML</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POINT (-122.24289 47.43721)</td>\n",
       "      <td>Qaw</td>\n",
       "      <td>0.272720</td>\n",
       "      <td>1.453522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.62921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10503</th>\n",
       "      <td>153203</td>\n",
       "      <td>B-3</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.46</td>\n",
       "      <td>47.437427</td>\n",
       "      <td>-122.243398</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>POINT (-122.2434 47.43743)</td>\n",
       "      <td>Qaw</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>1.009704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.62921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10504</th>\n",
       "      <td>153204</td>\n",
       "      <td>B-4</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>69.0</td>\n",
       "      <td>26.78</td>\n",
       "      <td>47.436984</td>\n",
       "      <td>-122.243486</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>POINT (-122.24349 47.43698)</td>\n",
       "      <td>Qaw</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>1.009704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.62921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10505</th>\n",
       "      <td>153205</td>\n",
       "      <td>B-5</td>\n",
       "      <td>Geotechnical</td>\n",
       "      <td>54.0</td>\n",
       "      <td>23.75</td>\n",
       "      <td>47.437412</td>\n",
       "      <td>-122.242456</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>POINT (-122.24246 47.43741)</td>\n",
       "      <td>Qaw</td>\n",
       "      <td>0.373783</td>\n",
       "      <td>1.591432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.62921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10506 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BOREHOLE_ID BOREHOLE_NAME BOREHOLE_TYPE  BOREHOLE_DEPTH_FT  \\\n",
       "0                7          EB-1  Geotechnical               41.0   \n",
       "1                8          EB-2  Geotechnical               40.0   \n",
       "2               15          HB-1  Geotechnical               10.5   \n",
       "3               16          HB-2  Geotechnical                6.9   \n",
       "4               17          HB-3  Geotechnical               13.5   \n",
       "...            ...           ...           ...                ...   \n",
       "10501       153201           B-1  Geotechnical               44.0   \n",
       "10502       153202           B-2  Geotechnical               39.0   \n",
       "10503       153203           B-3  Geotechnical               44.0   \n",
       "10504       153204           B-4  Geotechnical               69.0   \n",
       "10505       153205           B-5  Geotechnical               54.0   \n",
       "\n",
       "       ELEVATION_FT   LATITUDE   LONGITUDE  LAYER_NUMBER  TOP_DEPTH_FT  \\\n",
       "0            131.30  47.575005 -122.406037             1           0.0   \n",
       "1            130.90  47.574982 -122.406239             1           0.0   \n",
       "2             46.30  47.512358 -122.394125             1           0.0   \n",
       "3             47.70  47.512384 -122.394069             1           0.0   \n",
       "4             40.90  47.512208 -122.394083             1           0.0   \n",
       "...             ...        ...         ...           ...           ...   \n",
       "10501         26.35  47.437003 -122.242410             1           0.0   \n",
       "10502         24.45  47.437208 -122.242890             1           0.0   \n",
       "10503         24.46  47.437427 -122.243398             1           0.0   \n",
       "10504         26.78  47.436984 -122.243486             1           0.0   \n",
       "10505         23.75  47.437412 -122.242456             1           0.0   \n",
       "\n",
       "       BOTTOM_DEPTH_FT USCS SIMPLE_USCS  LAYER_THICKNESS_FT  \\\n",
       "0                  2.5   OH           O                 2.5   \n",
       "1                  5.0   SC           S                 5.0   \n",
       "2                  7.5   ML           M                 7.5   \n",
       "3                  5.0   ML           M                 5.0   \n",
       "4                  8.6   ML           M                 8.6   \n",
       "...                ...  ...         ...                 ...   \n",
       "10501              0.5  NaN         NaN                 0.5   \n",
       "10502              2.0   ML           M                 2.0   \n",
       "10503              0.5  NaN         NaN                 0.5   \n",
       "10504              0.5  NaN         NaN                 0.5   \n",
       "10505              0.5  NaN         NaN                 0.5   \n",
       "\n",
       "                          geometry MAPPED_UNIT      SLOPE  ROUGHNESS  \\\n",
       "0        POINT (-122.40604 47.575)          Ql   8.126739  36.531616   \n",
       "1      POINT (-122.40624 47.57498)          Ql   8.056191  38.262520   \n",
       "2      POINT (-122.39412 47.51236)         Qss  12.098481  45.003693   \n",
       "3      POINT (-122.39407 47.51238)         Qss  12.098481  45.003693   \n",
       "4      POINT (-122.39408 47.51221)         Qss  12.098481  45.003693   \n",
       "...                            ...         ...        ...        ...   \n",
       "10501    POINT (-122.24241 47.437)         Qaw   0.373783   1.591432   \n",
       "10502  POINT (-122.24289 47.43721)         Qaw   0.272720   1.453522   \n",
       "10503   POINT (-122.2434 47.43743)         Qaw   0.158798   1.009704   \n",
       "10504  POINT (-122.24349 47.43698)         Qaw   0.158798   1.009704   \n",
       "10505  POINT (-122.24246 47.43741)         Qaw   0.373783   1.591432   \n",
       "\n",
       "       GEOMORPHON       VS30  \n",
       "0             6.0  647.38780  \n",
       "1             6.0  647.38780  \n",
       "2             5.0        NaN  \n",
       "3             5.0        NaN  \n",
       "4             5.0        NaN  \n",
       "...           ...        ...  \n",
       "10501         1.0  191.62921  \n",
       "10502         1.0  191.62921  \n",
       "10503         1.0  191.62921  \n",
       "10504         1.0  191.62921  \n",
       "10505         1.0  191.62921  \n",
       "\n",
       "[10506 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data CSV file compiled in `1-data_access.ipynb`\n",
    "input_file = '../data/2.1-seattle_layer1_trainingdata.csv'\n",
    "training_data = pd.read_csv(input_file)\n",
    "\n",
    "# Create a GeoDataFrame from the DataFrame\n",
    "training_data = gpd.GeoDataFrame(training_data, geometry=gpd.points_from_xy(training_data.LONGITUDE, training_data.LATITUDE))\n",
    "    \n",
    "# Set the CRS to WGS84 (latitude and longitude)\n",
    "training_data.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb9989-deeb-486b-8e0f-fe3f457fd7f6",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b471b6f-3014-4f81-9d7b-379e2d8e682c",
   "metadata": {},
   "source": [
    "#### Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46a3a7a-5e3a-4e14-b974-91b4a6720104",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data[['MAPPED_UNIT', 'SLOPE', 'ROUGHNESS', 'VS30', 'GEOMORPHON']]\n",
    "y_1 = training_data['SIMPLE_USCS']\n",
    "y_2 = training_data['LAYER_THICKNESS_FT']\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), ['MAPPED_UNIT', 'GEOMORPHON']),  # One-hot encode categorical features\n",
    "        ('num', StandardScaler(), ['SLOPE', 'ROUGHNESS', 'VS30'])  # Standardize numerical features\n",
    "    ])\n",
    "\n",
    "# Drop rows with NaN values in X and corresponding y_1 and y_2\n",
    "X = X.dropna()\n",
    "y_1 = y_1.loc[X.index].dropna()  # Ensure y_1 is aligned with X and has no NaN values\n",
    "y_2 = y_2.loc[X.index].dropna()  # Ensure y_2 is aligned with X and has no NaN values\n",
    "\n",
    "# Handle cases where dropping NaN results in mismatched lengths\n",
    "X = X.loc[y_1.index]  # Align X with the remaining non-NaN y_1\n",
    "y_2 = y_2.loc[y_1.index]  # Align y_2 with the remaining non-NaN y_1\n",
    "\n",
    "# Apply transformations to X\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_tensor = torch.tensor(X_processed.todense(), dtype=torch.float32) if scipy.sparse.issparse(X_processed) else torch.tensor(X_processed, dtype=torch.float32) \n",
    "\n",
    "# Handling target for SIMPLE_USCS\n",
    "label_encoder = LabelEncoder()\n",
    "y_1_encoded = label_encoder.fit_transform(y_1)\n",
    "y_1_tensor = torch.tensor(y_1_encoded, dtype=torch.long)\n",
    "\n",
    "# Handling target for LAYER_THICKNESS_FT\n",
    "scaler = StandardScaler()\n",
    "y_2_scaled = scaler.fit_transform(y_2.values.reshape(-1, 1))\n",
    "y_2_tensor = torch.tensor(y_2_scaled, dtype=torch.float32).squeeze()\n",
    "\n",
    "# Split the data into training and test sets for both models\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_tensor, y_1_tensor, test_size=0.2, random_state=42, stratify=y_1_tensor)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_tensor, y_2_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90866c21-8195-430d-8e42-61261992ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPClassificationModel(ApproximateGP):\n",
    "    def __init__(self, train_x, num_classes):\n",
    "        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, train_x, variational_distribution, learn_inducing_locations=True)\n",
    "        super(GPClassificationModel, self).__init__(variational_strategy)\n",
    "        \n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x).expand([self.num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aae8782-58f7-402a-a911-b0ef4dc501c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPRegressionModel(ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = ScaleKernel(RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09725995-8ee9-4094-a996-483cfa12c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the likelihood and model for multiclass classification\n",
    "num_classes = len(label_encoder.classes_)\n",
    "likelihood_1 = gpytorch.likelihoods.SoftmaxLikelihood(num_classes=num_classes, mixing_weights=None)\n",
    "model_1 = GPClassificationModel(X_train_1, num_classes=num_classes)\n",
    "\n",
    "# Initialize the likelihood and model for regression\n",
    "likelihood_2 = GaussianLikelihood()\n",
    "model_2 = GPRegressionModel(X_train_2, y_train_2, likelihood_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "186fdab4-64a0-4155-8381-77c30651925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): SoftmaxLikelihood()\n",
       "  (1): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a ModuleList to store the models\n",
    "models = torch.nn.ModuleList([model_1, model_2])\n",
    "likelihoods = torch.nn.ModuleList([likelihood_1, likelihood_2])\n",
    "\n",
    "# Set into eval mode for all models and likelihoods\n",
    "models.eval()\n",
    "likelihoods.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31ec59-1b17-4549-b339-1790ae7c1f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Model Iter 1/100 - Loss: 2.0684492588043213\n",
      "Classification Model Iter 2/100 - Loss: 2.0736007690429688\n",
      "Classification Model Iter 3/100 - Loss: 2.054042100906372\n",
      "Classification Model Iter 4/100 - Loss: 2.0347936153411865\n",
      "Classification Model Iter 5/100 - Loss: 2.0281169414520264\n",
      "Classification Model Iter 6/100 - Loss: 2.0118088722229004\n",
      "Classification Model Iter 7/100 - Loss: 1.9758926630020142\n",
      "Classification Model Iter 8/100 - Loss: 1.9519052505493164\n",
      "Classification Model Iter 9/100 - Loss: 1.9476325511932373\n",
      "Classification Model Iter 10/100 - Loss: 1.9393813610076904\n",
      "Classification Model Iter 11/100 - Loss: 1.9235185384750366\n",
      "Classification Model Iter 12/100 - Loss: 1.9197428226470947\n",
      "Classification Model Iter 13/100 - Loss: 1.915328860282898\n",
      "Classification Model Iter 14/100 - Loss: 1.9140287637710571\n",
      "Classification Model Iter 15/100 - Loss: 1.9088892936706543\n",
      "Classification Model Iter 16/100 - Loss: 1.90705406665802\n",
      "Classification Model Iter 17/100 - Loss: 1.9064586162567139\n",
      "Classification Model Iter 18/100 - Loss: 1.8996238708496094\n",
      "Classification Model Iter 19/100 - Loss: 1.9018539190292358\n",
      "Classification Model Iter 20/100 - Loss: 1.8953568935394287\n",
      "Classification Model Iter 21/100 - Loss: 1.8940035104751587\n",
      "Classification Model Iter 22/100 - Loss: 1.8943159580230713\n",
      "Classification Model Iter 23/100 - Loss: 1.8927109241485596\n",
      "Classification Model Iter 24/100 - Loss: 1.8902770280838013\n",
      "Classification Model Iter 25/100 - Loss: 1.8867688179016113\n",
      "Classification Model Iter 26/100 - Loss: 1.8867695331573486\n",
      "Classification Model Iter 27/100 - Loss: 1.886512279510498\n",
      "Classification Model Iter 28/100 - Loss: 1.8829030990600586\n",
      "Classification Model Iter 29/100 - Loss: 1.8837409019470215\n",
      "Classification Model Iter 30/100 - Loss: 1.8836069107055664\n",
      "Classification Model Iter 31/100 - Loss: 1.882901906967163\n",
      "Classification Model Iter 32/100 - Loss: 1.8794667720794678\n",
      "Classification Model Iter 33/100 - Loss: 1.881592035293579\n",
      "Classification Model Iter 34/100 - Loss: 1.8784079551696777\n",
      "Classification Model Iter 35/100 - Loss: 1.8775839805603027\n",
      "Classification Model Iter 36/100 - Loss: 1.8801072835922241\n",
      "Classification Model Iter 37/100 - Loss: 1.8758915662765503\n",
      "Classification Model Iter 38/100 - Loss: 1.8763302564620972\n",
      "Classification Model Iter 39/100 - Loss: 1.875232458114624\n",
      "Classification Model Iter 40/100 - Loss: 1.8754169940948486\n",
      "Classification Model Iter 41/100 - Loss: 1.874287724494934\n",
      "Classification Model Iter 42/100 - Loss: 1.8723222017288208\n",
      "Classification Model Iter 43/100 - Loss: 1.8716386556625366\n",
      "Classification Model Iter 44/100 - Loss: 1.8711999654769897\n",
      "Classification Model Iter 45/100 - Loss: 1.8711762428283691\n",
      "Classification Model Iter 46/100 - Loss: 1.866557240486145\n",
      "Classification Model Iter 47/100 - Loss: 1.870117425918579\n",
      "Classification Model Iter 48/100 - Loss: 1.8695623874664307\n",
      "Classification Model Iter 49/100 - Loss: 1.866776466369629\n",
      "Classification Model Iter 50/100 - Loss: 1.8669191598892212\n",
      "Classification Model Iter 51/100 - Loss: 1.8655861616134644\n",
      "Classification Model Iter 52/100 - Loss: 1.8658114671707153\n",
      "Classification Model Iter 53/100 - Loss: 1.8662238121032715\n",
      "Classification Model Iter 54/100 - Loss: 1.864139199256897\n",
      "Classification Model Iter 55/100 - Loss: 1.8637936115264893\n",
      "Classification Model Iter 56/100 - Loss: 1.8651173114776611\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "training_iter = 100  # Number of training iterations\n",
    "lr = 0.01  # Learning rate\n",
    "\n",
    "model_1.train()\n",
    "likelihood_1.train()\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(model_1.parameters(), lr=lr)\n",
    "mll_1 = gpytorch.mlls.VariationalELBO(likelihood_1, model_1, num_data=X_train_1.size(0))\n",
    "\n",
    "# Implement Gradient Clipping\n",
    "for i in range(training_iter):\n",
    "    optimizer_1.zero_grad()\n",
    "    output_1 = model_1(X_train_1)\n",
    "    \n",
    "    # Check for NaNs in the output\n",
    "    if torch.isnan(output_1.mean).any():\n",
    "        print(f\"Warning: NaN detected in output at iteration {i + 1}\")\n",
    "        break\n",
    "    \n",
    "    loss_1 = -mll_1(output_1, y_train_1)\n",
    "    loss_1.backward()\n",
    "    \n",
    "    # Clip gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model_1.parameters(), max_norm=1.0)\n",
    "    \n",
    "    optimizer_1.step()\n",
    "    print(f'Classification Model Iter {i + 1}/{training_iter} - Loss: {loss_1.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bedf33-d4cd-4ed1-bf78-55cfc3cff5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set models and likelihoods to evaluation mode\n",
    "# model_1.eval()\n",
    "# likelihood_1.eval()\n",
    "\n",
    "# # Make predictions (use a small batch from X_test_1 for diagnosis)\n",
    "# with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#     small_X_test_1 = X_test_1[:5]  # Take the first 5 samples for a small test\n",
    "#     prediction = model_1(small_X_test_1)\n",
    "    \n",
    "#     # Inspect the raw prediction mean before applying softmax\n",
    "#     print(f\"Raw prediction mean (pre-softmax): {prediction.mean}\")\n",
    "\n",
    "#     # Apply softmax and check the outputs\n",
    "#     predicted_probabilities = torch.softmax(prediction.mean, dim=0)\n",
    "#     print(f\"Predicted probabilities: {predicted_probabilities}\")\n",
    "\n",
    "#     predicted_labels = predicted_probabilities.argmax(dim=0).detach().numpy()\n",
    "#     print(f\"Predicted labels: {predicted_labels}\")\n",
    "\n",
    "# # If everything seems fine in the small batch, proceed with the full prediction\n",
    "# if not torch.isnan(prediction.mean).any():\n",
    "#     print(\"Small batch predictions are valid, proceeding with full test set.\")\n",
    "#     with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#         full_prediction = model_1(X_test_1)\n",
    "#         full_predicted_probabilities = torch.softmax(full_prediction.mean, dim=0)\n",
    "#         if torch.isnan(full_predicted_probabilities).any():\n",
    "#             print(\"NaN detected in full predictions!\")\n",
    "#         else:\n",
    "#             full_predicted_labels = full_predicted_probabilities.argmax(dim=0).detach().numpy()\n",
    "#             print(f\"Full predicted labels: {full_predicted_labels}\")\n",
    "# else:\n",
    "#     print(\"NaN detected in small batch predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e94fa1-82f3-4f8f-b0ab-08485e5ba361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Model Training\n",
    "model_2.train()\n",
    "likelihood_2.train()\n",
    "\n",
    "optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.1)\n",
    "mll_2 = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood_2, model_2)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    optimizer_2.zero_grad()\n",
    "    output_2 = model_2(X_train_2)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss_2 = -mll_2(output_2, y_train_2)\n",
    "    \n",
    "    loss_2.backward()\n",
    "    optimizer_2.step()\n",
    "    print(f'Regression Model Iter {i + 1}/{training_iter} - Loss: {loss_2.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a9885-3c31-4912-9bd3-59dbd8f8c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set models and likelihoods to evaluation mode\n",
    "model_1.eval()\n",
    "model_2.eval()\n",
    "likelihood_1.eval()\n",
    "likelihood_2.eval()\n",
    "\n",
    "# Initialize plots\n",
    "f, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Make predictions (use the test tensors X_train_1 and X_train_2)\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    predictions = [likelihood(model(X_train)) for model, likelihood, X_train in zip(models, likelihoods, [X_train_1, X_train_2])]\n",
    "\n",
    "# Iterate through the models and predictions\n",
    "for i, (submodel, prediction, ax) in enumerate(zip(models, predictions, axs)):\n",
    "    if i == 0:  # Classification Model\n",
    "        predicted_probabilities = torch.softmax(prediction.mean, dim=0)  # Apply softmax across the class dimension\n",
    "        predicted_labels = predicted_probabilities.argmax(dim=0).detach().numpy()  # Use argmax on the class dimension\n",
    "        print(predicted_probabilities)\n",
    "        print(predicted_labels)\n",
    "        \n",
    "        # Ensure y_train_1 is flattened to match the predicted_labels shape\n",
    "        y_train_1_flat = y_train_1.numpy().flatten()\n",
    "\n",
    "        # Plot Predicted vs Observed labels\n",
    "        if y_train_1_flat.shape == predicted_labels.shape:\n",
    "            ax.scatter(y_train_1_flat, predicted_labels, c='b', marker='o')  # Scatter plot of predicted vs observed\n",
    "            ax.plot([0, len(label_encoder.classes_) - 1], [0, len(label_encoder.classes_) - 1], 'r--')  # Diagonal line for reference\n",
    "            ax.set_title('Classification: Predicted vs Observed')\n",
    "            ax.set_xlabel('Observed Labels')\n",
    "            ax.set_ylabel('Predicted Labels')\n",
    "            ax.set_xlim([0, len(label_encoder.classes_) - 1])\n",
    "            ax.set_ylim([0, len(label_encoder.classes_) - 1])\n",
    "            ax.legend(['Reference Line', 'Predicted vs Observed'])\n",
    "        else:\n",
    "            print(\"Warning: Shapes of y_train_1 and predicted_labels do not match!\")\n",
    "\n",
    "    else:  # Regression Model\n",
    "        mean = prediction.mean\n",
    "        lower, upper = prediction.confidence_region()\n",
    "\n",
    "        # Reverse the standardization for the mean and confidence intervals\n",
    "        mean_unscaled = scaler.inverse_transform(mean.numpy().reshape(-1, 1)).flatten()\n",
    "        lower_unscaled = scaler.inverse_transform(lower.numpy().reshape(-1, 1)).flatten()\n",
    "        upper_unscaled = scaler.inverse_transform(upper.numpy().reshape(-1, 1)).flatten()\n",
    "        y_train_unscaled = scaler.inverse_transform(y_train_2.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Plot the unscaled test data and predictions\n",
    "        ax.plot(range(len(y_train_unscaled)), y_train_unscaled, 'k*')  # Plot the unscaled test targets\n",
    "        ax.plot(range(len(mean_unscaled)), mean_unscaled, 'b')  # Unscaled predictive mean as blue line\n",
    "        # Shade in confidence interval\n",
    "        ax.fill_between(range(len(mean_unscaled)), lower_unscaled, upper_unscaled, alpha=0.5)\n",
    "        ax.set_ylim([min(lower_unscaled), max(upper_unscaled)])  # Adjust the y-axis limits\n",
    "        ax.set_title('Regression: Mean and Confidence Interval (Unscaled)')\n",
    "        ax.legend(['Observed Data (Unscaled)', 'Mean (Unscaled)', 'Confidence Interval'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e76c9-8c6f-4ce9-8b47-17235d141861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize plots\n",
    "f, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Make predictions (use the test tensors X_test_1 and X_test_2)\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    predictions = [likelihood(model(X_test)) for model, likelihood, X_test in zip(models, likelihoods, [X_test_1, X_test_2])]\n",
    "\n",
    "# Iterate through the models and predictions\n",
    "for i, (submodel, prediction, ax) in enumerate(zip(models, predictions, axs)):\n",
    "    if i == 0:  # Classification Model\n",
    "        predicted_probabilities = torch.softmax(prediction.mean, dim=0)  # Apply softmax across the class dimension\n",
    "        predicted_labels = predicted_probabilities.argmax(dim=0).detach().numpy()  # Use argmax on the class dimension\n",
    "        print(predicted_probabilities)\n",
    "        print(predicted_labels)\n",
    "\n",
    "        # Ensure y_test_1 is flattened to match the predicted_labels shape\n",
    "        y_test_1_flat = y_test_1.numpy().flatten()\n",
    "\n",
    "        # Plot Predicted vs Observed labels\n",
    "        if y_test_1_flat.shape == predicted_labels.shape:\n",
    "            ax.scatter(y_test_1_flat, predicted_labels, c='b', marker='o')  # Scatter plot of predicted vs observed\n",
    "            ax.plot([0, len(label_encoder.classes_) - 1], [0, len(label_encoder.classes_) - 1], 'r--')  # Diagonal line for reference\n",
    "            ax.set_title('Classification: Predicted vs Observed')\n",
    "            ax.set_xlabel('Observed Labels')\n",
    "            ax.set_ylabel('Predicted Labels')\n",
    "            ax.set_xlim([0, len(label_encoder.classes_) - 1])\n",
    "            ax.set_ylim([0, len(label_encoder.classes_) - 1])\n",
    "            ax.legend(['Reference Line', 'Predicted vs Observed'])\n",
    "        else:\n",
    "            print(\"Warning: Shapes of y_test_1 and predicted_labels do not match!\")\n",
    "\n",
    "    else:  # Regression Model\n",
    "        mean = prediction.mean\n",
    "        lower, upper = prediction.confidence_region()\n",
    "\n",
    "        # Reverse the standardization for the mean and confidence intervals\n",
    "        mean_unscaled = scaler.inverse_transform(mean.numpy().reshape(-1, 1)).flatten()\n",
    "        lower_unscaled = scaler.inverse_transform(lower.numpy().reshape(-1, 1)).flatten()\n",
    "        upper_unscaled = scaler.inverse_transform(upper.numpy().reshape(-1, 1)).flatten()\n",
    "        y_test_unscaled = scaler.inverse_transform(y_test_2.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "        # # Plot the unscaled test data and predictions\n",
    "        # ax.plot(range(len(y_test_unscaled)), y_test_unscaled, 'k*')  # Plot the unscaled test targets\n",
    "        # ax.plot(range(len(mean_unscaled)), mean_unscaled, 'b')  # Unscaled predictive mean as blue line\n",
    "        # # Shade in confidence interval\n",
    "        # ax.fill_between(range(len(mean_unscaled)), lower_unscaled, upper_unscaled, alpha=0.5)\n",
    "        # ax.set_ylim([min(lower_unscaled), max(upper_unscaled)])  # Adjust the y-axis limits\n",
    "        # ax.set_title('Regression: Mean and Confidence Interval (Unscaled)')\n",
    "        # ax.legend(['Observed Data (Unscaled)', 'Prediction Mean (Unscaled)', 'Confidence Interval'])        \n",
    "        ax.scatter(y_test_unscaled, mean_unscaled, c='blue', alpha=0.6, edgecolors='k', label='Predicted vs Observed')\n",
    "        ax.set_xlim(0,60)\n",
    "        ax.set_ylim(0,60)\n",
    "        ax.set_xlabel('Observed')\n",
    "        ax.set_ylabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9572ab2-b989-44a2-b38a-ce10837c2663",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd695f-7b66-46d9-a6d9-2c605f8cdca9",
   "metadata": {},
   "source": [
    "Sources:\n",
    "1. https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/ModelList_GP_Regression.html\n",
    "2. https://jamesbrind.uk/posts/2d-gaussian-process-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c0ff8-2357-4fc0-ace3-79768843c4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
